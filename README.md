# ğŸ¨ Sistema de Treinamento de GANs

Sistema completo e unificado para treinar **Generative Adversarial Networks (GANs)** com mÃºltiplos datasets e arquiteturas. Desenvolvido para ser **fÃ¡cil de usar**, **portÃ¡til** e **pronto para compartilhar**.

## âš¡ InÃ­cio Ultra-RÃ¡pido

```bash
# 1. Instalar dependÃªncias
pip install -r requirements.txt

# 2. Usar menu interativo (recomendado!)
./run.sh

# OU treinar direto via linha de comando
python train.py --dataset mnist --model dcgan --epochs 25
```

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Como Usar](#-como-usar)
  - [Menu Interativo](#1-menu-interativo-recomendado)
  - [Linha de Comando](#2-linha-de-comando)
  - [Gerar Imagens](#3-gerar-imagens)
- [Datasets DisponÃ­veis](#-datasets-disponÃ­veis)
- [Modelos GAN](#-modelos-gan)
- [Exemplos PrÃ¡ticos](#-exemplos-prÃ¡ticos)
- [ParÃ¢metros AvanÃ§ados](#ï¸-parÃ¢metros-avanÃ§ados)
- [Estrutura de SaÃ­da](#-estrutura-de-saÃ­da)
- [Troubleshooting](#-troubleshooting)
- [FAQ](#-faq)

## âœ¨ CaracterÃ­sticas

- ğŸš€ **Menu interativo** - Configure tudo sem digitar comandos
- ğŸ“¦ **5 datasets** - CIFAR-10, MNIST, Fashion-MNIST, CelebA, Custom
- ğŸ¤– **2 arquiteturas GAN** - DCGAN e WGAN-GP
- ğŸ’¾ **Checkpoints automÃ¡ticos** - Retome treinamento a qualquer momento
- ğŸ“Š **VisualizaÃ§Ã£o em tempo real** - Perdas e amostras geradas
- âš¡ **Suporte GPU/CPU** - Detecta CUDA automaticamente
- ğŸ¯ **Download automÃ¡tico** - Datasets baixados automaticamente
- ğŸ“ **Logs detalhados** - Acompanhe todo o processo

## ğŸ“¥ InstalaÃ§Ã£o

```bash
# 1. Clonar repositÃ³rio
git clone https://github.com/seu-usuario/projeto-geracao-imagem.git
cd projeto-geracao-imagem

# 2. Instalar dependÃªncias
pip install -r requirements.txt

# 3. Dar permissÃ£o ao script (Linux/Mac)
chmod +x run.sh

# 4. Verificar instalaÃ§Ã£o
python train.py --list-datasets
```

### Requisitos

- Python 3.8+
- PyTorch 2.0+
- CUDA (opcional, mas recomendado para GPU)
- 4GB+ RAM (CPU) ou 4GB+ VRAM (GPU)

## ğŸš€ Como Usar

### 1. Menu Interativo (Recomendado!)

O jeito mais fÃ¡cil de usar o sistema:

```bash
./run.sh
```

O menu permite:

- âœ… Treinar novos modelos (com assistente passo-a-passo)
- âœ… Gerar imagens de modelos existentes
- âœ… Listar datasets e modelos disponÃ­veis
- âœ… Ver status do treinamento
- âœ… Configurar tudo de forma intuitiva

**Exemplo de uso:**

1. Execute `./run.sh`
2. Escolha opÃ§Ã£o `1` (Treinar novo modelo)
3. Selecione dataset (ex: `2` para MNIST)
4. Selecione modelo (ex: `1` para DCGAN)
5. Configure Ã©pocas (ex: `25`)
6. Confirme e deixe treinar!

### 2. Linha de Comando

Para usuÃ¡rios avanÃ§ados ou automaÃ§Ã£o:

```bash
# Sintaxe bÃ¡sica
python train.py --dataset <dataset> --model <modelo> --epochs <num>

# Exemplo: MNIST com DCGAN
python train.py --dataset mnist --model dcgan --epochs 25

# Exemplo: CIFAR-10 com WGAN-GP
python train.py --dataset cifar10 --model wgan-gp --epochs 100

# Ver todas as opÃ§Ãµes
python train.py --help
```

### 3. Gerar Imagens

ApÃ³s treinar, gere imagens do seu modelo:

#### OpÃ§Ã£o A: Modo automÃ¡tico (mais fÃ¡cil)

```bash
python quick_generate.py
```

- Encontra automaticamente o Ãºltimo modelo treinado
- Pergunta quantas imagens gerar
- Salva no mesmo diretÃ³rio do modelo

#### OpÃ§Ã£o B: Especificar checkpoint

```bash
python generate.py \
  --checkpoint outputs/mnist/dcgan_20241107_120540/checkpoints/checkpoint_latest.pth \
  --num-samples 64 \
  --output minha_imagem.png
```

#### OpÃ§Ã£o C: Via menu interativo

```bash
./run.sh
# Escolha opÃ§Ã£o 2 (Gerar imagens)
```

## ğŸ“¦ Datasets DisponÃ­veis

| Dataset           | DescriÃ§Ã£o                                     | Imagens  | Download     | Tamanho  | Canais |
| ----------------- | --------------------------------------------- | -------- | ------------ | -------- | ------ |
| **CIFAR-10**      | 10 categorias coloridas (aviÃµes, carros, etc) | 60.000   | âœ… AutomÃ¡tico | 32x32    | RGB    |
| **MNIST**         | DÃ­gitos 0-9 escritos Ã  mÃ£o                    | 70.000   | âœ… AutomÃ¡tico | 28x28    | Gray   |
| **Fashion-MNIST** | Roupas e acessÃ³rios (10 categorias)           | 70.000   | âœ… AutomÃ¡tico | 28x28    | Gray   |
| **CelebA**        | Faces de celebridades                         | ~200.000 | âš ï¸ Manual     | 178x218  | RGB    |
| **Custom**        | Suas prÃ³prias imagens                         | VariÃ¡vel | ğŸ“ Local      | VariÃ¡vel | RGB    |

### Ver lista completa

```bash
python train.py --list-datasets
```

### Usar dataset customizado

### 1. Organize suas imagens

```bash
data/
â””â”€â”€ custom/
    â””â”€â”€ sua_categoria/
        â”œâ”€â”€ imagem1.jpg
        â”œâ”€â”€ imagem2.png
        â””â”€â”€ ...
```

### 2. Treine

```bash
python train.py --dataset custom --model dcgan --epochs 100
```

## ğŸ¤– Modelos GAN

### 1. DCGAN (Deep Convolutional GAN)

> **Recomendado para: Iniciantes, treinamento rÃ¡pido**

```bash
python train.py --dataset mnist --model dcgan --epochs 25
```

**CaracterÃ­sticas:**

- âœ… EstÃ¡vel e fÃ¡cil de treinar
- âœ… Bons resultados com configuraÃ§Ãµes padrÃ£o
- âœ… Mais rÃ¡pido (~2x que WGAN-GP)
- ğŸ“„ Paper: [Radford et al., 2015](https://arxiv.org/abs/1511.06434)

**ConfiguraÃ§Ãµes padrÃ£o:**

- Learning rate: `0.0002`
- Beta1: `0.5`
- Otimizador: Adam

### 2. WGAN-GP (Wasserstein GAN + Gradient Penalty)

Recomendado para: Melhor qualidade, projetos sÃ©rios

```bash
python train.py --dataset cifar10 --model wgan-gp --epochs 100
```

**CaracterÃ­sticas:**

- âœ… Treinamento mais estÃ¡vel
- âœ… Menos mode collapse
- âœ… Melhor qualidade de imagens
- âš ï¸ Mais lento (5x treino do discriminador)
- ğŸ“„ Paper: [Gulrajani et al., 2017](https://arxiv.org/abs/1704.00028)

**ConfiguraÃ§Ãµes padrÃ£o:**

- Learning rate: `0.0001`
- Beta1: `0.0`
- N_critic: `5` (treina critic 5x por batch)
- Lambda_gp: `10.0` (gradient penalty)

### Ver lista completa de modelos

```bash
python train.py --list-models
```

## ğŸ’¡ Exemplos PrÃ¡ticos

### ğŸ¯ Teste RÃ¡pido (5 minutos)

```bash
python train.py --dataset mnist --model dcgan --epochs 5 --batch-size 128
```

### ğŸš€ Treinamento BÃ¡sico (30 minutos)

```bash
python train.py --dataset mnist --model dcgan --epochs 25
```

### ğŸ¨ Qualidade MÃ©dia (1-2 horas)

```bash
python train.py --dataset cifar10 --model dcgan --epochs 50 --batch-size 64
```

### â­ Alta Qualidade (3-5 horas)

```bash
python train.py --dataset cifar10 --model wgan-gp --epochs 200 --batch-size 64
```

### ğŸ–¼ï¸ Imagens de Alta ResoluÃ§Ã£o 128px (2-3 horas)

```bash
python train.py --dataset cifar10 --model dcgan --img-size 128 --epochs 50 --batch-size 64
```

### ğŸ–¼ï¸ Imagens de AltÃ­ssima ResoluÃ§Ã£o 256px (5+ horas)

```bash
python train.py --dataset celeba --model dcgan --img-size 256 --ngf 128 --ndf 128 --epochs 100 --batch-size 32
```

### ğŸ’¾ GPU com Pouca MemÃ³ria (RTX 4060 8GB)

```bash
# 128px - batch-size 64 recomendado
python train.py --dataset fashion-mnist --model dcgan --img-size 128 --batch-size 64 --workers 2

# 256px - batch-size 32 recomendado
python train.py --dataset cifar10 --model dcgan --img-size 256 --batch-size 32 --ngf 96 --ndf 96
```

### ğŸ“ Dataset Customizado

```bash
python train.py --dataset custom --model dcgan --epochs 100 --img-size 64
```

## âš™ï¸ ParÃ¢metros AvanÃ§ados

### ParÃ¢metros Principais

```bash
python train.py \
  --dataset <nome>         # Dataset: cifar10, mnist, fashion-mnist, celeba, custom
  --model <nome>           # Modelo: dcgan, wgan-gp
  --epochs <num>           # NÃºmero de Ã©pocas (padrÃ£o: 50)
  --batch-size <num>       # Tamanho do batch (padrÃ£o: 128)
  --img-size <num>         # Tamanho da imagem (padrÃ£o: 128, presets: 128/256, mÃ­nimo: 128)
  --lr <float>             # Learning rate (auto-detectado se omitido)
  --nz <num>               # DimensÃ£o do vetor latente (padrÃ£o: 100)
  --ngf <num>              # Filtros do gerador (padrÃ£o: 64, use 96-128 para 256px)
  --ndf <num>              # Filtros do discriminador (padrÃ£o: 64, use 96-128 para 256px)
  --workers <num>          # Workers do DataLoader (padrÃ£o: 2)
  --ngpu <num>             # NÃºmero de GPUs (padrÃ£o: 1)
```

### Exemplos de ConfiguraÃ§Ãµes

#### Aumentar capacidade do modelo

```bash
--ngf 128 --ndf 128  # Mais filtros = mais capacidade
```

#### Ajustar learning rate

```bash
--lr 0.0001  # Menor = mais estÃ¡vel, mais lento
--lr 0.0005  # Maior = mais rÃ¡pido, menos estÃ¡vel
```

#### Usar mÃºltiplas GPUs

```bash
--ngpu 2  # Usar 2 GPUs
```

#### Processar mais dados em paralelo

```bash
--workers 4  # Mais workers = carregamento mais rÃ¡pido
```

### Ver todas as opÃ§Ãµes

```bash
python train.py --help
```

## ğŸ“‚ Estrutura de SaÃ­da

ApÃ³s o treinamento, os resultados sÃ£o salvos em `outputs/`:

```bash
outputs/
â””â”€â”€ <dataset>/
    â””â”€â”€ <modelo>_<timestamp>/
        â”œâ”€â”€ config.json              # âš™ï¸ ConfiguraÃ§Ãµes usadas
        â”œâ”€â”€ training.log             # ğŸ“ Log completo do treinamento
        â”œâ”€â”€ training_losses.png      # ğŸ“Š GrÃ¡fico de perdas
        â”œâ”€â”€ final_samples.png        # ğŸ¨ Imagens finais geradas
        â”œâ”€â”€ samples/                 # ğŸ“¸ Amostras por Ã©poca
        â”‚   â”œâ”€â”€ epoch_5.png
        â”‚   â”œâ”€â”€ epoch_10.png
        â”‚   â””â”€â”€ ...
        â””â”€â”€ checkpoints/             # ğŸ’¾ Modelos salvos
            â”œâ”€â”€ checkpoint_epoch_10.pth
            â”œâ”€â”€ checkpoint_epoch_20.pth
            â””â”€â”€ checkpoint_latest.pth  # â­ Ãšltimo checkpoint
```

### Exemplo real

```bash
outputs/mnist/dcgan_20241107_120540/
â”œâ”€â”€ config.json                    # HiperparÃ¢metros usados
â”œâ”€â”€ training.log                   # "Epoch 1/25, Loss_D: 0.5, Loss_G: 1.2, ..."
â”œâ”€â”€ training_losses.png            # GrÃ¡fico D_loss vs G_loss
â”œâ”€â”€ final_samples.png              # Grid 8x8 de imagens geradas
â”œâ”€â”€ samples/
â”‚   â”œâ”€â”€ epoch_5.png               # Como estava na Ã©poca 5
â”‚   â”œâ”€â”€ epoch_10.png
â”‚   â””â”€â”€ epoch_25.png
â””â”€â”€ checkpoints/
    â”œâ”€â”€ checkpoint_epoch_10.pth   # Checkpoint da Ã©poca 10 (75MB)
    â”œâ”€â”€ checkpoint_epoch_20.pth   # Checkpoint da Ã©poca 20 (75MB)
    â””â”€â”€ checkpoint_latest.pth     # Checkpoint final (75MB)
```

### O que cada checkpoint contÃ©m

- âœ… Pesos completos do gerador
- âœ… Pesos completos do discriminador
- âœ… Estados dos otimizadores
- âœ… ConfiguraÃ§Ãµes do modelo
- âœ… HistÃ³rico de perdas
- âœ… Ã‰poca atual

**VocÃª pode retomar o treinamento de qualquer checkpoint!**

## ğŸ’¾ Checkpoints - Guia Completo

### ğŸ“ Onde ficam os checkpoints?

Os checkpoints sÃ£o salvos automaticamente durante o treinamento em:

```
outputs/<dataset>/<modelo>_<timestamp>/checkpoints/
```

Exemplo:
```
outputs/mnist/dcgan_20241207_143022/checkpoints/
â”œâ”€â”€ checkpoint_epoch_10.pth      # Salvo na Ã©poca 10
â”œâ”€â”€ checkpoint_epoch_20.pth      # Salvo na Ã©poca 20
â””â”€â”€ checkpoint_latest.pth        # Sempre o mais recente â­
```

### ğŸš€ Como usar checkpoints para geraÃ§Ã£o

**MÃ©todo 1: AutomÃ¡tico (recomendado)**

```bash
python quick_generate.py
# Encontra automaticamente o Ãºltimo checkpoint e gera imagens
```

**MÃ©todo 2: Especificar checkpoint**

```bash
python generate.py \
  --checkpoint outputs/mnist/dcgan_20241207_143022/checkpoints/checkpoint_latest.pth \
  --num-samples 64 \
  --upscale 2x
```

**MÃ©todo 3: GeraÃ§Ã£o interativa com upscale**

```bash
python generate_interactive.py \
  --checkpoint outputs/cifar10/dcgan_xxx/checkpoints/checkpoint_latest.pth \
  --upscale 8 \
  --upscale-method lanczos
```

### ğŸ¨ OpÃ§Ãµes de upscale na geraÃ§Ã£o

Todos os scripts de geraÃ§Ã£o agora suportam upscaling pÃ³s-processamento:

```bash
# Sem upscale (padrÃ£o no generate.py)
python generate.py --checkpoint <path> --upscale none

# Upscale 2x
python generate.py --checkpoint <path> --upscale 2x

# Upscale 4x com mÃ©todo bicubic
python generate.py --checkpoint <path> --upscale 4x --upscale-method bicubic

# Upscale 8x com lanczos (melhor qualidade)
python generate.py --checkpoint <path> --upscale 8x --upscale-method lanczos
```

**MÃ©todos disponÃ­veis:**
- `lanczos` - Melhor qualidade (padrÃ£o)
- `bicubic` - RÃ¡pido e bom
- `nearest` - Pixel-perfect (estilo retro)

### ğŸ”„ Como retomar treinamento (futura implementaÃ§Ã£o)

```bash
# Retomar do Ãºltimo checkpoint
python train.py --resume outputs/mnist/dcgan_xxx/checkpoints/checkpoint_latest.pth

# Retomar de Ã©poca especÃ­fica
python train.py --resume outputs/mnist/dcgan_xxx/checkpoints/checkpoint_epoch_20.pth
```

> **Nota:** A funcionalidade de retomar treinamento serÃ¡ implementada em breve.

### ğŸ“¦ Como transportar para outra mÃ¡quina

**Passo 1: Preparar para transporte**

```bash
# Criar pacote com checkpoint e config
cd outputs/mnist/dcgan_20241207_143022
zip -r meu_modelo.zip checkpoints/checkpoint_latest.pth config.json

# Ou copiar apenas o essencial
cp checkpoints/checkpoint_latest.pth ~/modelo_mnist.pth
cp config.json ~/modelo_mnist_config.json
```

**Passo 2: Na mÃ¡quina de destino**

```bash
# 1. Instalar dependÃªncias
pip install -r requirements.txt

# 2. Criar estrutura de diretÃ³rios
mkdir -p outputs/mnist/modelo_importado/checkpoints

# 3. Copiar arquivos
cp modelo_mnist.pth outputs/mnist/modelo_importado/checkpoints/checkpoint_latest.pth
cp modelo_mnist_config.json outputs/mnist/modelo_importado/config.json

# 4. Gerar imagens
python generate.py \
  --checkpoint outputs/mnist/modelo_importado/checkpoints/checkpoint_latest.pth \
  --num-samples 64
```

### ğŸ’¡ Dicas de portabilidade

âœ… **O que levar:**
- `checkpoint_latest.pth` (essencial) - ~50-150MB
- `config.json` (essencial) - <1KB
- `training_losses.png` (opcional) - HistÃ³rico visual
- `final_samples.png` (opcional) - Exemplos de saÃ­da

âœ… **Sistemas compatÃ­veis:**
- Windows, Linux, macOS
- GPU (CUDA) ou CPU
- Python 3.8+

âœ… **Compartilhamento:**
- GitHub Releases (<100MB)
- Google Drive / Dropbox
- Hugging Face Hub (recomendado para >100MB)

### ğŸ“Š Tamanho dos checkpoints

| Modelo | ResoluÃ§Ã£o | ngf/ndf | Tamanho aprox. |
|--------|-----------|---------|----------------|
| DCGAN  | 128px     | 64      | ~50MB          |
| DCGAN  | 256px     | 64      | ~50MB          |
| DCGAN  | 256px     | 128     | ~150MB         |
| WGAN-GP| 128px     | 64      | ~50MB          |
| WGAN-GP| 256px     | 128     | ~150MB         |

### ğŸ¯ Exemplo completo: Compartilhar modelo treinado

```bash
# 1. Na mÃ¡quina de origem (apÃ³s treinar)
cd outputs/mnist/dcgan_20241207_143022
zip -r mnist_dcgan_trained.zip \
  checkpoints/checkpoint_latest.pth \
  config.json \
  final_samples.png \
  training_losses.png

# 2. Compartilhar mnist_dcgan_trained.zip (GitHub, Drive, etc)

# 3. Na mÃ¡quina de destino
unzip mnist_dcgan_trained.zip -d imported_model/

# 4. Gerar imagens
python generate.py \
  --checkpoint imported_model/checkpoints/checkpoint_latest.pth \
  --num-samples 100 \
  --upscale 4x
```

## ğŸ”§ Troubleshooting

### âŒ "CUDA out of memory"

**SoluÃ§Ã£o:** Reduza batch size ou tamanho da imagem

```bash
python train.py --dataset mnist --model dcgan --batch-size 32 --img-size 32
```

### âŒ "No module named 'torch'"

**SoluÃ§Ã£o:** Instale PyTorch

```bash
pip install torch torchvision
```

### âŒ "RuntimeError: CUDA not available"

**SoluÃ§Ã£o:** Treine na CPU (mais lento, mas funciona)

```bash
# O cÃ³digo detecta automaticamente e usa CPU
python train.py --dataset mnist --model dcgan --epochs 10
```

### âŒ "FileNotFoundError: data/custom not found"

**SoluÃ§Ã£o:** Crie a estrutura de pastas correta

```bash
mkdir -p data/custom/sua_categoria
# Coloque suas imagens em data/custom/sua_categoria/
```

### âŒ Treinamento muito lento

**SoluÃ§Ãµes:**

```bash
# 1. Use GPU se disponÃ­vel
nvidia-smi  # Verifica se GPU estÃ¡ disponÃ­vel

# 2. Reduza epochs para testes
python train.py --dataset mnist --model dcgan --epochs 5

# 3. Use dataset menor
python train.py --dataset mnist --model dcgan  # Mais rÃ¡pido que cifar10

# 4. Use DCGAN em vez de WGAN-GP
python train.py --dataset cifar10 --model dcgan  # 2x mais rÃ¡pido
```

### âŒ Imagens geradas ruins

**SoluÃ§Ãµes:**

```bash
# 1. Treine por mais Ã©pocas
python train.py --dataset mnist --model dcgan --epochs 50

# 2. Use WGAN-GP para melhor qualidade
python train.py --dataset mnist --model wgan-gp --epochs 100

# 3. Ajuste learning rate
python train.py --dataset mnist --model dcgan --lr 0.0001

# 4. Aumente capacidade do modelo
python train.py --dataset mnist --model dcgan --ngf 128 --ndf 128
```

### âŒ "Mode collapse" (imagens todas iguais)

**SoluÃ§Ã£o:** Use WGAN-GP

```bash
python train.py --dataset cifar10 --model wgan-gp --epochs 100
```

## â“ FAQ

### Q: Quanto tempo leva para treinar?

**A:** Depende do dataset e hardware:

- **MNIST (DCGAN, GPU):** ~10-15 minutos (25 Ã©pocas)
- **CIFAR-10 (DCGAN, GPU):** ~1-2 horas (50 Ã©pocas)
- **CIFAR-10 (WGAN-GP, GPU):** ~3-5 horas (100 Ã©pocas)
- **CelebA (DCGAN, GPU):** ~5-8 horas (100 Ã©pocas)
- **CPU:** ~10-20x mais lento que GPU

### Q: Preciso de GPU?

**A:** NÃ£o Ã© obrigatÃ³rio, mas **fortemente recomendado**:

- âœ… GPU: Treinamento em horas
- âŒ CPU: Treinamento em dias

### Q: Qual modelo usar?

**A:**

- **Iniciante/Teste:** DCGAN (mais rÃ¡pido, mais fÃ¡cil)
- **Qualidade/ProduÃ§Ã£o:** WGAN-GP (melhor resultado, mais lento)

### Q: Quantas Ã©pocas treinar?

**A:** RecomendaÃ§Ãµes:

- **MNIST:** 25-50 Ã©pocas
- **Fashion-MNIST:** 50-75 Ã©pocas
- **CIFAR-10:** 50-100 Ã©pocas (DCGAN) ou 100-200 (WGAN-GP)
- **CelebA:** 100-200 Ã©pocas

### Q: Como usar minhas prÃ³prias imagens?

**A:**

1. Crie pasta: `data/custom/categoria/`
2. Coloque suas imagens (.jpg, .png)
3. Execute: `python train.py --dataset custom --model dcgan --epochs 100`
4. Recomendado: 10.000+ imagens para bons resultados

### Q: Posso retomar um treinamento interrompido?

**A:** Sim! (em desenvolvimento - serÃ¡ adicionado em breve)

### Q: Como compartilhar meu modelo treinado?

**A:**

1. **Compactar checkpoint:**

   ```bash
   cd outputs/mnist/dcgan_xxx/checkpoints/
   zip meu_modelo.zip checkpoint_latest.pth
   ```

2. **Compartilhar via:**
   - GitHub Releases (recomendado para <2GB)
   - Google Drive / Dropbox
   - Hugging Face Hub

3. **Outros podem usar:**

   ```bash
   python generate.py --checkpoint checkpoint_latest.pth --num-samples 100
   ```

### Q: Qual tamanho de batch usar?

**A:** Depende da memÃ³ria da GPU e resoluÃ§Ã£o:

**Para 128px (padrÃ£o):**
- **16GB+ VRAM:** batch-size 128-256
- **8GB VRAM (RTX 4060):** batch-size 64-128
- **4GB VRAM:** batch-size 32-64
- **CPU:** batch-size 32

**Para 256px:**
- **16GB+ VRAM:** batch-size 64-128
- **8GB VRAM (RTX 4060):** batch-size 32-64
- **4GB VRAM:** batch-size 16-32
- **CPU:** batch-size 16

### Q: O que Ã© "mode collapse"?

**A:** Quando o gerador produz sempre as mesmas imagens. **SoluÃ§Ã£o:** Use WGAN-GP.

### Q: Como melhorar a qualidade das imagens?

**A:**

1. Treine por mais Ã©pocas
2. Use WGAN-GP em vez de DCGAN
3. Aumente capacidade: `--ngf 128 --ndf 128`
4. Use dataset maior e de melhor qualidade
5. Ajuste learning rate: `--lr 0.0001`

## ğŸ“š Recursos de Aprendizado

- ğŸ“„ **DCGAN Paper:** <https://arxiv.org/abs/1511.06434>
- ğŸ“„ **WGAN-GP Paper:** <https://arxiv.org/abs/1704.00028>
- ğŸ“– **PyTorch Tutorials:** <https://pytorch.org/tutorials/>
- ğŸ“ **GANs Course:** <https://www.coursera.org/learn/generative-adversarial-networks-gans>

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas!

Para adicionar:

- **Novo dataset:** Edite `config.py` â†’ funÃ§Ã£o `get_dataset()`
- **Novo modelo:** Edite `models.py` â†’ adicione classe do modelo
- **Nova feature:** Abra um Pull Request

## ğŸ“ LicenÃ§a

Projeto open source - Use e modifique livremente!

## ğŸ¯ PrÃ³ximos Passos

1. **Instale as dependÃªncias:**

   ```bash
   pip install -r requirements.txt
   ```

2. **Execute o menu interativo:**

   ```bash
   ./run.sh
   ```

3. **Ou faÃ§a seu primeiro treinamento:**

   ```bash
   python train.py --dataset mnist --model dcgan --epochs 25
   ```

4. **Gere imagens:**

   ```bash
   python quick_generate.py
   ```

5. **Experimente outros datasets e modelos!**

## ğŸ“ Suporte

- ğŸ› **Bug?** Abra uma [issue](https://github.com/seu-usuario/projeto-geracao-imagem/issues)
- ğŸ’¡ **SugestÃ£o?** Abra uma [discussion](https://github.com/seu-usuario/projeto-geracao-imagem/discussions)
- â­ **Gostou?** DÃª uma estrela no projeto!

> **Bom treinamento! ğŸš€ğŸ¨**
